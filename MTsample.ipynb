{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MTsample.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU39Pk7dtCZb"
      },
      "source": [
        "# FairSeqを用いた機械翻訳\n",
        "https://github.com/pytorch/fairseq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWyp48hGuax1"
      },
      "source": [
        "## 1. ライブラリのインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VV6hSXesoZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a151956-e3e1-47f5-c144-d3ab53badead"
      },
      "source": [
        "# Pythonのバージョンが3.6以上であることを確認\n",
        "import sys\n",
        "print(sys.version)\n",
        "\n",
        "# PyTorchのバージョンが1.5.0以上であることを確認\n",
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7.12 (default, Sep 10 2021, 00:21:48) \n",
            "[GCC 7.5.0]\n",
            "1.9.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5Pj1dzPttYg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 909
        },
        "outputId": "482cba3e-b263-4044-b83d-352b5ab25668"
      },
      "source": [
        "# インストール\n",
        "! pip install fairseq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fairseq\n",
            "  Downloading fairseq-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.9.0+cu111)\n",
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 42.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.29.24)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq) (2019.12.20)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.14.6)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq) (4.62.3)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq) (2.20)\n",
            "Collecting omegaconf==2.1.*\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (5.2.2)\n",
            "Collecting PyYAML>=5.1.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 38.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core->fairseq) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq) (3.7.4.3)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=d283093137b5ca1c94dd989433f37a3fe3515065b01718eb03d5c1bc71552c20\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, dataclasses, fairseq\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.8 colorama-0.4.4 dataclasses-0.6 fairseq-0.10.2 hydra-core-1.1.1 omegaconf-2.1.1 portalocker-2.3.2 sacrebleu-2.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dataclasses",
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHYgqehDt_iA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38686265-63bd-4fba-d828-2b200d16e436"
      },
      "source": [
        "# fairseqのバージョン確認\n",
        "! pip show fairseq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: fairseq\n",
            "Version: 0.10.2\n",
            "Summary: Facebook AI Research Sequence-to-Sequence Toolkit\n",
            "Home-page: https://github.com/pytorch/fairseq\n",
            "Author: None\n",
            "Author-email: None\n",
            "License: UNKNOWN\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: torch, cython, dataclasses, regex, numpy, tqdm, sacrebleu, cffi, hydra-core\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WN0luVLuhOf"
      },
      "source": [
        "## 2. 日英対訳データの準備\n",
        "https://github.com/odashi/small_parallel_enja"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVw4WAauuvsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c13b30e6-0035-4ce6-b63f-6061a9f452eb"
      },
      "source": [
        "# ダウンロード\n",
        "! git clone https://github.com/odashi/small_parallel_enja.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'small_parallel_enja'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Total 35 (delta 0), reused 0 (delta 0), pack-reused 35\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfSCE937vvAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e2f20a-39e4-48c1-d823-ef8e18084942"
      },
      "source": [
        "# データサイズ（行数）の確認\n",
        "! wc -l ./small_parallel_enja/*.en ./small_parallel_enja/*.ja"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    500 ./small_parallel_enja/dev.en\n",
            "    500 ./small_parallel_enja/test.en\n",
            "  50000 ./small_parallel_enja/train.en\n",
            "    500 ./small_parallel_enja/dev.ja\n",
            "    500 ./small_parallel_enja/test.ja\n",
            "  50000 ./small_parallel_enja/train.ja\n",
            " 102000 total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hWG2yynwB4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "495b4c7f-c92c-4277-ca8d-1bff34ae91ff"
      },
      "source": [
        "# データ内容の確認\n",
        "! head -3 ./small_parallel_enja/train.en ./small_parallel_enja/train.ja"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> ./small_parallel_enja/train.en <==\n",
            "i can 't tell who will arrive first .\n",
            "many animals have been destroyed by men .\n",
            "i 'm in the tennis club .\n",
            "\n",
            "==> ./small_parallel_enja/train.ja <==\n",
            "誰 が 一番 に 着 く か 私 に は 分か り ま せ ん 。\n",
            "多く の 動物 が 人間 に よ っ て 滅ぼ さ れ た 。\n",
            "私 は テニス 部員 で す 。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk8ed_IrwlhJ"
      },
      "source": [
        "普通は次に単語分割をしますが、今回のデータは分割済みなのでスキップします。\n",
        "\n",
        "単語分割にはSentencePieceなどのツールを使います。\n",
        "\n",
        "https://github.com/google/sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruttHlq8vcYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53a658d-fbb1-4da7-b068-5843bfa6a196"
      },
      "source": [
        "# データ形式の変更\n",
        "DATA = \"/content/small_parallel_enja\"\n",
        "! fairseq-preprocess --source-lang en --target-lang ja --trainpref $DATA/train --validpref $DATA/dev --testpref $DATA/test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-22 02:24:44 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='en', srcdict=None, target_lang='ja', task='translation', tensorboard_logdir=None, testpref='/content/small_parallel_enja/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/content/small_parallel_enja/train', user_dir=None, validpref='/content/small_parallel_enja/dev', workers=1)\n",
            "2021-10-22 02:24:48 | INFO | fairseq_cli.preprocess | [en] Dictionary: 6640 types\n",
            "2021-10-22 02:24:51 | INFO | fairseq_cli.preprocess | [en] /content/small_parallel_enja/train.en: 50000 sents, 441047 tokens, 0.0% replaced by <unk>\n",
            "2021-10-22 02:24:51 | INFO | fairseq_cli.preprocess | [en] Dictionary: 6640 types\n",
            "2021-10-22 02:24:51 | INFO | fairseq_cli.preprocess | [en] /content/small_parallel_enja/dev.en: 500 sents, 4431 tokens, 0.451% replaced by <unk>\n",
            "2021-10-22 02:24:51 | INFO | fairseq_cli.preprocess | [en] Dictionary: 6640 types\n",
            "2021-10-22 02:24:51 | INFO | fairseq_cli.preprocess | [en] /content/small_parallel_enja/test.en: 500 sents, 4498 tokens, 0.622% replaced by <unk>\n",
            "2021-10-22 02:24:51 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 8784 types\n",
            "2021-10-22 02:24:55 | INFO | fairseq_cli.preprocess | [ja] /content/small_parallel_enja/train.ja: 50000 sents, 615618 tokens, 0.0% replaced by <unk>\n",
            "2021-10-22 02:24:55 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 8784 types\n",
            "2021-10-22 02:24:55 | INFO | fairseq_cli.preprocess | [ja] /content/small_parallel_enja/dev.ja: 500 sents, 6168 tokens, 0.519% replaced by <unk>\n",
            "2021-10-22 02:24:55 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 8784 types\n",
            "2021-10-22 02:24:55 | INFO | fairseq_cli.preprocess | [ja] /content/small_parallel_enja/test.ja: 500 sents, 6135 tokens, 0.603% replaced by <unk>\n",
            "2021-10-22 02:24:55 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shVnb6Qz0HIJ"
      },
      "source": [
        "## 3. 翻訳器の訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "setxRARx0F4G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2c6f64-3565-40c4-aee0-331f32d4bbfc"
      },
      "source": [
        "! fairseq-train data-bin --arch transformer \\\n",
        "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 400 \\\n",
        "    --dropout 0.3 --clip-norm 0.0 \\\n",
        "    --optimizer adam --max-tokens 4096 --max-epoch 5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-22 02:27:51 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.999)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=5, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=400, weight_decay=0.0, zero_sharding='none')\n",
            "2021-10-22 02:27:51 | INFO | fairseq.tasks.translation | [en] dictionary: 6640 types\n",
            "2021-10-22 02:27:51 | INFO | fairseq.tasks.translation | [ja] dictionary: 8784 types\n",
            "2021-10-22 02:27:51 | INFO | fairseq.data.data_utils | loaded 500 examples from: data-bin/valid.en-ja.en\n",
            "2021-10-22 02:27:51 | INFO | fairseq.data.data_utils | loaded 500 examples from: data-bin/valid.en-ja.ja\n",
            "2021-10-22 02:27:51 | INFO | fairseq.tasks.translation | data-bin valid en-ja 500 examples\n",
            "2021-10-22 02:27:52 | INFO | fairseq_cli.train | TransformerModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(6640, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(8784, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (output_projection): Linear(in_features=512, out_features=8784, bias=False)\n",
            "  )\n",
            ")\n",
            "2021-10-22 02:27:52 | INFO | fairseq_cli.train | task: translation (TranslationTask)\n",
            "2021-10-22 02:27:52 | INFO | fairseq_cli.train | model: transformer (TransformerModel)\n",
            "2021-10-22 02:27:52 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)\n",
            "2021-10-22 02:27:52 | INFO | fairseq_cli.train | num. model params: 56532992 (num. trained: 56532992)\n",
            "2021-10-22 02:28:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-10-22 02:28:06 | INFO | fairseq.utils | rank   0: capabilities =  3.7  ; total memory = 11.173 GB ; name = Tesla K80                               \n",
            "2021-10-22 02:28:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-10-22 02:28:06 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2021-10-22 02:28:06 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None\n",
            "2021-10-22 02:28:06 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/checkpoint_last.pt\n",
            "2021-10-22 02:28:06 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2021-10-22 02:28:06 | INFO | fairseq.data.data_utils | loaded 50000 examples from: data-bin/train.en-ja.en\n",
            "2021-10-22 02:28:06 | INFO | fairseq.data.data_utils | loaded 50000 examples from: data-bin/train.en-ja.ja\n",
            "2021-10-22 02:28:06 | INFO | fairseq.tasks.translation | data-bin train en-ja 50000 examples\n",
            "epoch 001:   0% 0/158 [00:00<?, ?it/s]2021-10-22 02:28:06 | INFO | fairseq.trainer | begin training epoch 1\n",
            "/usr/local/lib/python3.7/dist-packages/fairseq/utils.py:342: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
            "epoch 001:  99% 157/158 [02:04<00:00,  1.22it/s, loss=9.52, nll_loss=8.986, ppl=507.11, wps=4934.8, ups=1.27, wpb=3896.6, bsz=314.1, num_updates=100, lr=0.000125, gnorm=3.536, train_wall=79, wall=79]2021-10-22 02:30:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  3.27it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.57it/s]\u001b[A\n",
            "                                                                      \u001b[A2021-10-22 02:30:12 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.588 | nll_loss 5.427 | ppl 43.01 | wps 7764.4 | wpb 2056 | bsz 166.7 | num_updates 158\n",
            "2021-10-22 02:30:12 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2021-10-22 02:30:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint1.pt (epoch 1 @ 158 updates, score 6.588) (writing took 16.906061259000126 seconds)\n",
            "2021-10-22 02:30:29 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2021-10-22 02:30:29 | INFO | train | epoch 001 | loss 8.6 | nll_loss 7.91 | ppl 240.51 | wps 4312.3 | ups 1.11 | wpb 3896.3 | bsz 316.5 | num_updates 158 | lr 0.0001975 | gnorm 3.234 | train_wall 125 | wall 143\n",
            "epoch 002:   0% 0/158 [00:00<?, ?it/s]2021-10-22 02:30:29 | INFO | fairseq.trainer | begin training epoch 2\n",
            "epoch 002:  99% 157/158 [02:03<00:00,  1.25it/s, loss=5.766, nll_loss=4.606, ppl=24.35, wps=4981.3, ups=1.27, wpb=3908.2, bsz=311.2, num_updates=300, lr=0.000375, gnorm=1.881, train_wall=78, wall=255]2021-10-22 02:32:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  3.20it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.48it/s]\u001b[A\n",
            "                                                                      \u001b[A2021-10-22 02:32:35 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 5.348 | nll_loss 4.062 | ppl 16.7 | wps 7544.9 | wpb 2056 | bsz 166.7 | num_updates 316 | best_loss 5.348\n",
            "2021-10-22 02:32:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2021-10-22 02:32:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint2.pt (epoch 2 @ 316 updates, score 5.348) (writing took 16.205016218000083 seconds)\n",
            "2021-10-22 02:32:51 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2021-10-22 02:32:51 | INFO | train | epoch 002 | loss 5.889 | nll_loss 4.748 | ppl 26.87 | wps 4350.1 | ups 1.12 | wpb 3896.3 | bsz 316.5 | num_updates 316 | lr 0.000395 | gnorm 1.925 | train_wall 124 | wall 285\n",
            "epoch 003:   0% 0/158 [00:00<?, ?it/s]2021-10-22 02:32:51 | INFO | fairseq.trainer | begin training epoch 3\n",
            "epoch 003:  99% 157/158 [02:03<00:00,  1.25it/s, loss=5.333, nll_loss=4.112, ppl=17.29, wps=4069.5, ups=1.04, wpb=3898, bsz=320.7, num_updates=400, lr=0.0005, gnorm=1.581, train_wall=79, wall=351]2021-10-22 02:34:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  3.24it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.58it/s]\u001b[A\n",
            "                                                                      \u001b[A2021-10-22 02:34:56 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.639 | nll_loss 3.249 | ppl 9.51 | wps 7883.4 | wpb 2056 | bsz 166.7 | num_updates 474 | best_loss 4.639\n",
            "2021-10-22 02:34:56 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2021-10-22 02:35:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint3.pt (epoch 3 @ 474 updates, score 4.639) (writing took 20.659443046999968 seconds)\n",
            "2021-10-22 02:35:17 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2021-10-22 02:35:17 | INFO | train | epoch 003 | loss 5.16 | nll_loss 3.915 | ppl 15.09 | wps 4220.4 | ups 1.08 | wpb 3896.3 | bsz 316.5 | num_updates 474 | lr 0.000459315 | gnorm 1.475 | train_wall 124 | wall 431\n",
            "epoch 004:   0% 0/158 [00:00<?, ?it/s]2021-10-22 02:35:17 | INFO | fairseq.trainer | begin training epoch 4\n",
            "epoch 004:  99% 157/158 [02:03<00:00,  1.29it/s, loss=4.615, nll_loss=3.291, ppl=9.79, wps=4959.8, ups=1.28, wpb=3878, bsz=309.4, num_updates=600, lr=0.000408248, gnorm=1.216, train_wall=78, wall=530]2021-10-22 02:37:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 004 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  3.06it/s]\u001b[A\n",
            "epoch 004 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.45it/s]\u001b[A\n",
            "                                                                      \u001b[A2021-10-22 02:37:22 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.309 | nll_loss 2.851 | ppl 7.22 | wps 7576.2 | wpb 2056 | bsz 166.7 | num_updates 632 | best_loss 4.309\n",
            "2021-10-22 02:37:22 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2021-10-22 02:37:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint4.pt (epoch 4 @ 632 updates, score 4.309) (writing took 19.003739068000186 seconds)\n",
            "2021-10-22 02:37:41 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
            "2021-10-22 02:37:41 | INFO | train | epoch 004 | loss 4.608 | nll_loss 3.284 | ppl 9.74 | wps 4282.3 | ups 1.1 | wpb 3896.3 | bsz 316.5 | num_updates 632 | lr 0.000397779 | gnorm 1.207 | train_wall 124 | wall 574\n",
            "epoch 005:   0% 0/158 [00:00<?, ?it/s]2021-10-22 02:37:41 | INFO | fairseq.trainer | begin training epoch 5\n",
            "epoch 005:  99% 157/158 [02:02<00:00,  1.26it/s, loss=4.344, nll_loss=2.981, ppl=7.89, wps=4002.1, ups=1.02, wpb=3925.2, bsz=323.8, num_updates=700, lr=0.000377964, gnorm=1.114, train_wall=78, wall=628]2021-10-22 02:39:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:   0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 005 | valid on 'valid' subset:  33% 1/3 [00:00<00:00,  3.27it/s]\u001b[A\n",
            "epoch 005 | valid on 'valid' subset:  67% 2/3 [00:00<00:00,  3.54it/s]\u001b[A\n",
            "                                                                      \u001b[A2021-10-22 02:39:45 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.088 | nll_loss 2.571 | ppl 5.94 | wps 7840.9 | wpb 2056 | bsz 166.7 | num_updates 790 | best_loss 4.088\n",
            "2021-10-22 02:39:45 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2021-10-22 02:40:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint5.pt (epoch 5 @ 790 updates, score 4.088) (writing took 19.860906849000003 seconds)\n",
            "2021-10-22 02:40:05 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
            "2021-10-22 02:40:05 | INFO | train | epoch 005 | loss 4.254 | nll_loss 2.875 | ppl 7.34 | wps 4270.4 | ups 1.1 | wpb 3896.3 | bsz 316.5 | num_updates 790 | lr 0.000355784 | gnorm 1.079 | train_wall 123 | wall 718\n",
            "2021-10-22 02:40:05 | INFO | fairseq_cli.train | done training in 718.4 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDwms_Iw9yPR"
      },
      "source": [
        "## 4. 翻訳器の評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ive2Sz1R9x1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "275689bb-65d8-4e51-feaa-1ac87117d200"
      },
      "source": [
        "# 評価用データの翻訳\n",
        "! fairseq-generate data-bin --path checkpoints/checkpoint_best.pt --batch-size 128 --beam 5 > result.txt\n",
        "! head -20 result.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0% 0/4 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n",
            "2021-10-22 02:40:51 | INFO | fairseq_cli.generate | Namespace(all_gather_list_size=16384, batch_size=128, batch_size_valid=128, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='checkpoints/checkpoint_best.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, target_lang=None, task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2021-10-22 02:40:51 | INFO | fairseq.tasks.translation | [en] dictionary: 6640 types\n",
            "2021-10-22 02:40:51 | INFO | fairseq.tasks.translation | [ja] dictionary: 8784 types\n",
            "2021-10-22 02:40:51 | INFO | fairseq.data.data_utils | loaded 500 examples from: data-bin/test.en-ja.en\n",
            "2021-10-22 02:40:51 | INFO | fairseq.data.data_utils | loaded 500 examples from: data-bin/test.en-ja.ja\n",
            "2021-10-22 02:40:51 | INFO | fairseq.tasks.translation | data-bin test en-ja 500 examples\n",
            "2021-10-22 02:40:51 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/checkpoint_best.pt\n",
            "S-239\tthe airplane fell to the earth .\n",
            "T-239\t飛行 機 が 地面 に 落ち た 。\n",
            "H-239\t-1.1698551177978516\tその 飛行 機 は 飛行 機 で 寝 た 。\n",
            "D-239\t-1.1698551177978516\tその 飛行 機 は 飛行 機 で 寝 た 。\n",
            "P-239\t-0.4143 -3.3450 -0.0094 -0.0866 -3.8024 -0.0095 -1.4226 -3.0408 -0.5963 -0.1016 -0.0399\n",
            "S-366\tgive me the <unk> of it .\n",
            "T-366\tその 内訳 は ？\n",
            "H-366\t-0.8728818297386169\tそれ を 私 に や っ て くださ い 。\n",
            "D-366\t-0.8728818297386169\tそれ を 私 に や っ て くださ い 。\n",
            "P-366\t-0.7240 -0.9295 -1.3974 -0.3157 -3.4460 -0.2771 -0.0471 -2.0622 -0.2116 -0.1364 -0.0548\n",
            "S-493\tmay i have a road map ?\n",
            "T-493\t道路 地図 を 下さ い 。\n",
            "H-493\t-0.9543736577033997\t道 を 修理 し て も よろし い で す か 。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wp8kK7QAEzR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ef9a1c-042f-4d0e-8d98-befca241ffb2"
      },
      "source": [
        "# 出力ファイルから生成文を抽出\n",
        "! grep \"^H-\" result.txt | sort -V | cut -f3 > result.ja.txt\n",
        "! head result.ja.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "彼 ら は その 話 を し た 。\n",
            "彼 は 泳 ぐ 必要 は な かっ た 。\n",
            "彼 は 妹 と 同じ くらい 背 が 高 く な い 。\n",
            "１０ 時 前 に １０ 分 前 に 帰 っ て い る 。\n",
            "もう 少し 眠 っ て しま っ た 。\n",
            "彼女 は 私 たち の 隣 に 住 ん で い る 。\n",
            "あなた の 答え に 答え る こと が でき る 。\n",
            "私 は その 村 に 住 ん で い る 人 だ 。\n",
            "私 たち は この 試合 に 勝 っ て い る 。\n",
            "これ を どう し て くれ ま せ ん か 。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNNtOLrt-Kx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39af34cf-46c4-4f26-d71e-7653ac2f8f00"
      },
      "source": [
        "# BLEUスコアの計算（10エポック学習すると30点ぐらいのそこそこ良い翻訳になります）\n",
        "! fairseq-score --sys result.ja.txt --ref $DATA/test.ja"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(ignore_case=False, order=4, ref='/content/small_parallel_enja/test.ja', sacrebleu=False, sentence_bleu=False, sys='result.ja.txt')\n",
            "BLEU4 = 20.56, 53.0/28.7/15.7/8.9 (BP=0.957, ratio=0.958, syslen=5400, reflen=5635)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29OeFrFsE_dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41304678-f53c-4955-f860-9e7404d2667f"
      },
      "source": [
        "! head result.ja.txt $DATA/test.ja $DATA/test.en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> result.ja.txt <==\n",
            "彼 ら は その 話 を し た 。\n",
            "彼 は 泳 ぐ 必要 は な かっ た 。\n",
            "彼 は 妹 と 同じ くらい 背 が 高 く な い 。\n",
            "１０ 時 前 に １０ 分 前 に 帰 っ て い る 。\n",
            "もう 少し 眠 っ て しま っ た 。\n",
            "彼女 は 私 たち の 隣 に 住 ん で い る 。\n",
            "あなた の 答え に 答え る こと が でき る 。\n",
            "私 は その 村 に 住 ん で い る 人 だ 。\n",
            "私 たち は この 試合 に 勝 っ て い る 。\n",
            "これ を どう し て くれ ま せ ん か 。\n",
            "\n",
            "==> /content/small_parallel_enja/test.ja <==\n",
            "彼 ら は つい に それ が 真実 だ と 認め た 。\n",
            "彼 は 水泳 が 得意 で は な かっ た 。\n",
            "彼 は お 姉 さん に 劣 ら ず 親切 だ 。\n",
            "１０ 時 前 に 戻 ら な けれ ば な ら な い 。\n",
            "成功 を 祈 る わ 。\n",
            "彼女 は 私 たち の 隣 の 家 に す ん で い る 。\n",
            "あなた に 返事 を し よ う と し て い る ところ で す 。\n",
            "私 は 刹那 的 な 生き 方 を し て い る 人間 で す 。\n",
            "この 試合 は いただ き だ 。\n",
            "こんな こと を し た 理由 を 言 い な さ い 。\n",
            "\n",
            "==> /content/small_parallel_enja/test.en <==\n",
            "they finally acknowledged it as true .\n",
            "he didn 't care for swimming .\n",
            "he is no less kind than his sister .\n",
            "you must be back before ten .\n",
            "break a leg .\n",
            "she lives next door to us .\n",
            "i 'm about to tell you the answer .\n",
            "i 'm a person who lives for the moment .\n",
            "we have this game on ice .\n",
            "will you give me your reasons for doing this ?\n"
          ]
        }
      ]
    }
  ]
}